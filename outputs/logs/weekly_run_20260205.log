2026-02-05 13:51:46,011 - INFO - ==========================================
2026-02-05 13:51:46,012 - INFO - Weekly Run Started (Test Mode: True)
2026-02-05 13:51:46,012 - INFO - ==========================================
2026-02-05 13:51:46,012 - INFO - Starting Mock Data Generation: D:\shein-review-insights\demo\generate_mock_data.py
2026-02-05 13:51:50,039 - INFO - Finished Mock Data Generation successfully.
2026-02-05 13:51:50,039 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 13:52:32,923 - INFO - Finished Review Analysis & Report Generation successfully.
2026-02-05 13:52:32,924 - INFO - ==========================================
2026-02-05 13:52:32,924 - INFO - Weekly Run Completed Successfully
2026-02-05 13:52:32,925 - INFO - ==========================================
2026-02-05 13:52:32,925 - INFO - Outputs generated in D:\shein-review-insights\outputs
2026-02-05 13:57:22,450 - INFO - ==========================================
2026-02-05 13:57:22,450 - INFO - Weekly Run Started (Test Mode: True)
2026-02-05 13:57:22,450 - INFO - ==========================================
2026-02-05 13:57:22,450 - INFO - Starting Mock Data Generation: D:\shein-review-insights\demo\generate_mock_data.py
2026-02-05 13:57:23,479 - INFO - Finished Mock Data Generation successfully.
2026-02-05 13:57:23,479 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 13:57:51,442 - ERROR - Error during Review Analysis & Report Generation:
2026-02-05 13:57:51,443 - ERROR - Exit code: 1
2026-02-05 13:57:51,443 - ERROR - Stderr: Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.

Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<00:00, 11214.72it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<00:00, 5329.48it/s, Materializing param=embeddings.LayerNorm.bias] 
Loading weights:   2%|1         | 2/103 [00:00<00:00, 4346.43it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 3674.38it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 4018.82it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 3624.11it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 2127.74it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 2000.62it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/103 [00:00<00:00, 1752.74it/s, Materializing param=embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/103 [00:00<00:00, 1700.58it/s, Materializing param=embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 1826.39it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 1594.69it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 1637.85it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 1588.15it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 1657.58it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 1618.02it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 1653.25it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 1597.83it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 1693.16it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 1670.04it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 1711.14it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 1681.70it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1787.79it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1700.39it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1681.45it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1652.40it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 1684.56it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 1662.85it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 1723.40it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 1704.45it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 1788.57it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 1754.98it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 1826.51it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 1789.65it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 1861.01it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 1846.76it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 1920.05it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 1869.73it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 1908.24it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 1893.25it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 1875.29it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 1862.20it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 1911.00it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 1897.41it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 1918.94it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 1897.84it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 1949.10it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 1926.24it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 1970.53it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 1959.00it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 1982.19it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 1959.88it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2011.62it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2001.24it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2041.49it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2014.31it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2051.45it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2023.71it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2070.27it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2059.90it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2103.22it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2092.63it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2098.92it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2081.61it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2120.41it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2089.96it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2111.56it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2101.91it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2104.64it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2095.21it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2137.04it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2128.43it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2155.11it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2142.73it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2139.06it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2129.09it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2159.79it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2150.56it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2189.27it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2181.13it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2211.22it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2202.72it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2176.33it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2148.54it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2169.03it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2151.64it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2183.16it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2175.42it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2205.23it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2191.94it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2225.58it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2218.19it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2253.48it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2246.39it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2281.58it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2274.57it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2309.61it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2302.68it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2337.39it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2330.48it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2364.61it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2357.73it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2391.88it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2383.34it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2415.68it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2408.59it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2441.68it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2433.49it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2465.26it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2457.98it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2488.54it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2477.86it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2507.40it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2500.24it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2531.37it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2524.30it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2555.02it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2548.05it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2578.73it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2571.64it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2601.61it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2594.43it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2624.46it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2617.48it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2647.26it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2640.30it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2669.54it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2662.63it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2692.16it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2684.29it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2713.14it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2706.16it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2734.73it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2727.75it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2756.18it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2749.25it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2777.07it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2770.11it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2798.01it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2790.89it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2817.42it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2810.06it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2835.59it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2825.98it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 2846.56it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 2838.93it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 2864.06it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 2856.76it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 2881.89it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 2874.73it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 2899.04it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 2891.94it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 2917.68it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 2910.74it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 2936.24it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 2929.35it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 2954.26it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 2947.19it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 2972.02it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 2965.14it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 2990.16it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 2983.36it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 3008.14it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 3001.34it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 3025.61it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 3018.74it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 3043.03it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 3036.23it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 3060.48it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 3053.72it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 3078.02it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 3071.05it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 3094.30it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 3085.43it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 3108.20it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 3101.38it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 3124.47it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 3117.61it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 3140.49it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 3133.64it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 3156.19it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 3149.24it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 3171.68it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 3164.86it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 3187.16it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 3180.28it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 3202.30it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 3195.45it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 3217.32it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 3210.53it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 3232.27it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 3225.51it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 3246.83it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 3240.06it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 3261.77it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 3255.03it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 3275.40it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 3268.55it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 3289.81it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 3283.08it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 3304.33it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 3297.61it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 3318.74it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 3312.24it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3333.80it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3327.43it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3314.71it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.

Batches:   0%|          | 0/8 [00:00<?, ?it/s]
Batches:  12%|#2        | 1/8 [00:00<00:00,  7.19it/s]
Batches:  38%|###7      | 3/8 [00:00<00:00,  9.60it/s]
Batches:  62%|######2   | 5/8 [00:00<00:00, 10.64it/s]
Batches:  88%|########7 | 7/8 [00:00<00:00, 10.45it/s]
Batches: 100%|##########| 8/8 [00:00<00:00,  9.42it/s]
D:\shein-review-insights\venv\Lib\site-packages\huggingface_hub\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\singh\.cache\huggingface\hub\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
Traceback (most recent call last):
  File "D:\shein-review-insights\main.py", line 38, in <module>
    main()
    ~~~~^^
  File "D:\shein-review-insights\main.py", line 33, in main
    generate_detailed_breakdown(df_mapping, themes)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "D:\shein-review-insights\src\report_gen.py", line 128, in generate_detailed_breakdown
    pdf.multi_cell(0, 5, f"Sentiment Split: 1-2*: {fmt(low)} | 3*: {fmt(mid)} | 4-5*: {fmt(high)}")
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\shein-review-insights\venv\Lib\site-packages\fpdf\fpdf.py", line 242, in wrapper
    return fn(self, *args, **kwargs)
  File "D:\shein-review-insights\venv\Lib\site-packages\fpdf\deprecation.py", line 32, in wrapper
    return fn(self, *args, **kwargs)
  File "D:\shein-review-insights\venv\Lib\site-packages\fpdf\fpdf.py", line 4550, in multi_cell
    text_line = multi_line_break.get_line()
  File "D:\shein-review-insights\venv\Lib\site-packages\fpdf\line_break.py", line 792, in get_line
    raise FPDFException(
        "Not enough horizontal space to render a single character"
    )
fpdf.errors.FPDFException: Not enough horizontal space to render a single character

2026-02-05 13:57:51,444 - ERROR - Stdout: === SHEIN India Weekly Review Analyzer (Upgraded) ===
--- Task 1: Loading and Validating data/raw/shein_reviews_raw.csv ---
Validation passed: 300 reviews loaded.
--- Task 2: Cleaning Reviews ---
Filtered to reviews since 2025-11-13: 238 remaining.
Dropped short reviews (<5 words): 225 remaining.
Cleaned reviews saved to data/processed/reviews_clean.csv
--- Task 3 (Upgrade): Theme Discovery ---
Generating embeddings using all-MiniLM-L6-v2...
Clustering into 5 themes...
Initializing local LLM for theme naming...
LLM Naming failed: "Unknown task text2text-generation, available tasks are ['any-to-any', 'audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'keypoint-matching', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'token-classification', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']". Falling back to TF-IDF.
Initializing local LLM for theme naming...
LLM Naming failed: "Unknown task text2text-generation, available tasks are ['any-to-any', 'audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'keypoint-matching', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'token-classification', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']". Falling back to TF-IDF.
Initializing local LLM for theme naming...
LLM Naming failed: "Unknown task text2text-generation, available tasks are ['any-to-any', 'audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'keypoint-matching', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'token-classification', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']". Falling back to TF-IDF.
Initializing local LLM for theme naming...
LLM Naming failed: "Unknown task text2text-generation, available tasks are ['any-to-any', 'audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'keypoint-matching', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'token-classification', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']". Falling back to TF-IDF.
Initializing local LLM for theme naming...
LLM Naming failed: "Unknown task text2text-generation, available tasks are ['any-to-any', 'audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'keypoint-matching', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'token-classification', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']". Falling back to TF-IDF.
Saved review-to-theme mapping to data/processed/reviews_with_themes.csv
--- Task 4: Quote Selection ---
--- Task 5 & 6: Report Generation ---
Saved weekly_note.md
Saved email_draft.txt
--- Generating Detailed Theme Breakdown (MD & PDF) ---

2026-02-05 13:58:58,770 - INFO - ==========================================
2026-02-05 13:58:58,770 - INFO - Weekly Run Started (Test Mode: True)
2026-02-05 13:58:58,770 - INFO - ==========================================
2026-02-05 13:58:58,770 - INFO - Starting Mock Data Generation: D:\shein-review-insights\demo\generate_mock_data.py
2026-02-05 13:58:59,669 - INFO - Finished Mock Data Generation successfully.
2026-02-05 13:58:59,669 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 13:59:19,291 - INFO - Finished Review Analysis & Report Generation successfully.
2026-02-05 13:59:19,291 - INFO - ==========================================
2026-02-05 13:59:19,291 - INFO - Weekly Run Completed Successfully
2026-02-05 13:59:19,292 - INFO - ==========================================
2026-02-05 13:59:19,292 - INFO - Outputs generated in D:\shein-review-insights\outputs
2026-02-05 14:00:01,759 - INFO - ==========================================
2026-02-05 14:00:01,759 - INFO - Weekly Run Started (Test Mode: True)
2026-02-05 14:00:01,759 - INFO - ==========================================
2026-02-05 14:00:01,759 - INFO - Starting Mock Data Generation: D:\shein-review-insights\demo\generate_mock_data.py
2026-02-05 14:00:02,910 - INFO - Finished Mock Data Generation successfully.
2026-02-05 14:00:02,910 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 14:04:31,369 - INFO - Finished Review Analysis & Report Generation successfully.
2026-02-05 14:04:31,369 - INFO - ==========================================
2026-02-05 14:04:31,370 - INFO - Weekly Run Completed Successfully
2026-02-05 14:04:31,370 - INFO - ==========================================
2026-02-05 14:04:31,370 - INFO - Outputs generated in D:\shein-review-insights\outputs
2026-02-05 14:27:08,373 - INFO - ==========================================
2026-02-05 14:27:08,445 - INFO - Weekly Run Started (Test Mode: True)
2026-02-05 14:27:08,445 - INFO - ==========================================
2026-02-05 14:27:08,446 - INFO - Starting Mock Data Generation: D:\shein-review-insights\demo\generate_mock_data.py
2026-02-05 14:27:17,172 - INFO - Finished Mock Data Generation successfully.
2026-02-05 14:27:17,172 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 14:29:18,242 - INFO - Finished Review Analysis & Report Generation successfully.
2026-02-05 14:29:18,243 - INFO - ==========================================
2026-02-05 14:29:18,243 - INFO - Weekly Run Completed Successfully
2026-02-05 14:29:18,243 - INFO - ==========================================
2026-02-05 14:29:18,244 - INFO - Outputs generated in D:\shein-review-insights\outputs
2026-02-05 14:40:24,912 - INFO - ==========================================
2026-02-05 14:40:24,918 - INFO - Weekly Run Started (Test Mode: False)
2026-02-05 14:40:24,919 - INFO - ==========================================
2026-02-05 14:40:24,919 - INFO - Starting Real Review Scraping: D:\shein-review-insights\src\scrape_shein_india.py
2026-02-05 14:40:33,472 - INFO - Finished Real Review Scraping successfully.
2026-02-05 14:40:33,473 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 14:41:54,864 - INFO - Finished Review Analysis & Report Generation successfully.
2026-02-05 14:41:54,864 - INFO - ==========================================
2026-02-05 14:41:54,865 - INFO - Weekly Run Completed Successfully
2026-02-05 14:41:54,865 - INFO - ==========================================
2026-02-05 14:41:54,865 - INFO - Outputs generated in D:\shein-review-insights\outputs
2026-02-05 15:01:41,649 - INFO - ==========================================
2026-02-05 15:01:41,658 - INFO - Weekly Run Started (Test Mode: True)
2026-02-05 15:01:41,658 - INFO - ==========================================
2026-02-05 15:01:41,658 - INFO - Starting Mock Data Generation: D:\shein-review-insights\demo\generate_mock_data.py
2026-02-05 15:01:46,677 - INFO - Finished Mock Data Generation successfully.
2026-02-05 15:01:46,677 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 15:03:04,664 - INFO - Finished Review Analysis & Report Generation successfully.
2026-02-05 15:03:04,665 - INFO - ==========================================
2026-02-05 15:03:04,666 - INFO - Weekly Run Completed Successfully
2026-02-05 15:03:04,666 - INFO - ==========================================
2026-02-05 15:03:04,666 - INFO - Outputs generated in D:\shein-review-insights\outputs
2026-02-05 15:16:53,612 - INFO - ==========================================
2026-02-05 15:16:53,612 - INFO - Weekly Run Started (Test Mode: True)
2026-02-05 15:16:53,613 - INFO - ==========================================
2026-02-05 15:16:53,613 - INFO - Starting Mock Data Generation: D:\shein-review-insights\demo\generate_mock_data.py
2026-02-05 15:16:58,143 - INFO - Finished Mock Data Generation successfully.
2026-02-05 15:16:58,143 - INFO - Starting Review Analysis & Report Generation: D:\shein-review-insights\main.py
2026-02-05 15:18:12,802 - INFO - Finished Review Analysis & Report Generation successfully.
2026-02-05 15:18:12,803 - INFO - ==========================================
2026-02-05 15:18:12,803 - INFO - Weekly Run Completed Successfully
2026-02-05 15:18:12,803 - INFO - ==========================================
2026-02-05 15:18:12,804 - INFO - Outputs generated in D:\shein-review-insights\outputs
